Mapping the Collaboration between Crowdsourcing and Large Language Models: A Fine-Grained Survey

```markdown
* [Power-up! what can generative models do for human computation workflows?](https://arxiv.org/abs/2307.02243) [[arXiv 2023]](https://arxiv.org/abs/2307.02243)
* [Training a helpful and harmless assistant with reinforcement learning from human feedback](https://arxiv.org/abs/2204.05862) [[arXiv 2022]](https://arxiv.org/abs/2204.05862)
* [Ask the experts: sourcing a high-quality nutrition counseling dataset through human-ai collaboration](https://aclanthology.org/2024.findings-emnlp.762/) [[EMNLP 2024]](https://aclanthology.org/2024.findings-emnlp.762/)
* [Flexcrowd: Modeling the reliability of flexible annotations](https://dl.acm.org/doi/10.1145/3411764.3445585) [[CHI 2021]](https://dl.acm.org/doi/10.1145/3411764.3445585)
* [A review of public datasets in question answering research](https://dl.acm.org/doi/10.1145/3476415.3476420) [[ACM SIGIR Forum 2021]](https://dl.acm.org/doi/10.1145/3476415.3476420)
* [Chatgpt to replace crowdsourcing of paraphrases for intent classification: Higher diversity and comparable model robustness](https://arxiv.org/abs/2305.12947) [[arXiv 2023]](https://arxiv.org/abs/2305.12947)
* [Crowd-powered data mining](https://arxiv.org/abs/1801.03428) [[arXiv 2018]](https://arxiv.org/abs/1801.03428)
* [Redefining research crowdsourcing: Incorporating human feedback with Ilm-powered digital twins](https://dl.acm.org/doi/10.1145/3613905.3650742) [[CHI 2025]](https://dl.acm.org/doi/10.1145/3613905.3650742)
* [Interconnected neural linear contextual bandits with ucb exploration](https://link.springer.com/chapter/10.1007/978-3-031-05981-0_33) [[PAKDD 2022]](https://link.springer.com/chapter/10.1007/978-3-031-05981-0_33)
* [Active learning with crowd sourcing improves information retrieval](https://arxiv.org/abs/2309.02058) [[arXiv 2023]](https://arxiv.org/abs/2309.02058)
* [Towards personalized evaluation of large language models with an anonymous crowd-sourcing platform](https://dl.acm.org/doi/10.1145/3614458.3644026) [[WWW 2024]](https://dl.acm.org/doi/10.1145/3614458.3644026)
* [Gpts are multilingual annotators for sequence generation tasks](https://arxiv.org/abs/2402.05512) [[arXiv 2024]](https://arxiv.org/abs/2402.05512)
* [Crowdsourcing or ai sourcing?](https://dl.acm.org/doi/10.1145/3680236) [[CACM 2025]](https://dl.acm.org/doi/10.1145/3680236)
* [Towards crowd worker selection for crowdsourced testing task](http://www.jos.org.cn/jos/article/abstract/5391) [[Journal of Software 2018]](http://www.jos.org.cn/jos/article/abstract/5391)
* [Who should be selected to perform a task in crowdsourced testing?](https://ieeexplore.ieee.org/document/8029517) [[COMPSAC 2017]](https://ieeexplore.ieee.org/document/8029517)
* [Responsible crowdsourcing for responsible generative ai: Engaging crowds in ai auditing and evaluation](https://ojs.aaai.org/index.php/HCOMP/article/view/29653) [[HCOMP 2024]](https://ojs.aaai.org/index.php/HCOMP/article/view/29653)
* [Congret: Benchmarking fine-grained evaluation of retrieval augmented argumentation with Ilm judges](https://arxiv.org/abs/2402.05206) [[arXiv 2024]](https://arxiv.org/abs/2402.05206)
* [Fluid transformers and creative analogies: Exploring large language models' capacity for augmenting cross-domain analogical creativity](https://dl.acm.org/doi/10.1145/3591196.3593450) [[C&C 2023]](https://dl.acm.org/doi/10.1145/3591196.3593450)
* [Is gpt-3 text indistinguishable from human text? scarecrow: A framework for scrutinizing machine text](https://arxiv.org/abs/2107.01294) [[arXiv 2021]](https://arxiv.org/abs/2107.01294)
* [Perspectives on large language models for relevance judgment](https://dl.acm.org/doi/10.1145/3578337.3605128) [[ICTIR 2023]](https://dl.acm.org/doi/10.1145/3578337.3605128)
* [Sample-efficient human evaluation of large language models via maximum discrepancy competition](https://arxiv.org/abs/2404.08008) [[arXiv 2024]](https://arxiv.org/abs/2404.08008)
* [Truth knows no language: Evaluating truthfulness beyond english](https://arxiv.org/abs/2401.07705) [[arXiv 2024]](https://arxiv.org/abs/2401.07705)
* [Human evaluation of text style transfer: A user study](https://aclanthology.org/2020.acl-main.104/) [[ACL 2020]](https://aclanthology.org/2020.acl-main.104/)
* [The use of large language models to enhance cancer clinical trial educational materials](https://academic.oup.com/jncics/article/8/2/pkae019/7618991) [[JNCI Cancer Spectrum 2024]](https://academic.oup.com/jncics/article/8/2/pkae019/7618991)
* [The gem benchmark: Natural language generation, its evaluation and metrics](https://aclanthology.org/2021.acl-long.348/) [[ACL 2021]](https://aclanthology.org/2021.acl-long.348/)
* [Measuring social biases of crowd workers using counterfactual queries](https://arxiv.org/abs/2010.03844) [[arXiv 2020]](https://arxiv.org/abs/2010.03844)
* [Advancing content synthesis in macro-task crowd-sourcing facilitation leveraging natural language processing](https://link.springer.com/article/10.1007/s10726-024-09879-x) [[Group Decision and Negotiation 2024]](https://link.springer.com/article/10.1007/s10726-024-09879-x)
* [Llm-crowdsourced: A benchmark-free paradigm for mutual evaluation of large language models](https://arxiv.org/abs/2311.13023) [[arXiv 2023]](https://arxiv.org/abs/2311.13023)
* [Targen: Targeted data generation with large language models](https://arxiv.org/abs/2403.04022) [[arXiv 2024]](https://arxiv.org/abs/2403.04022)
* [Rebel: Rule-based and experience-enhanced learning with llms for initial task allocation in multi-human multi-robot teaming](https://arxiv.org/abs/2405.09700) [[arXiv 2024]](https://arxiv.org/abs/2405.09700)
* [Selecting workers like expert for crowdsourcing by integration evaluation of individual and collaborative abilities](https://www.sciencedirect.com/science/article/pii/S095741742401662X) [[Expert Systems with Applications 2024]](https://www.sciencedirect.com/science/article/pii/S095741742401662X)
* [From crowdsourcing to large multimodal models: Toward enhancing image data annotation with gpt-4v](https://arxiv.org/abs/2310.14324) [[arXiv 2023]](https://arxiv.org/abs/2310.14324)
* [Annollm: Making large language models to be better crowdsourced annotators](https://arxiv.org/abs/2303.16854) [[arXiv 2023]](https://arxiv.org/abs/2303.16854)
* [If in a Crowdsourced Data Annotation Pipeline, a GPT-4 Can Be a Good Annotator, How Can We Help It Be an Even Better One?](https://dl.acm.org/doi/10.1145/3613904.3642398) [[CHI 2024]](https://dl.acm.org/doi/10.1145/3613904.3642398)
* [Wikiwhy: Answering and explaining cause-and-effect questions](https://arxiv.org/abs/2210.12152) [[arXiv 2022]](https://arxiv.org/abs/2210.12152)
* [Conversational ai threads for visualizing multidimensional datasets](https://arxiv.org/abs/2311.05590) [[arXiv 2023]](https://arxiv.org/abs/2311.05590)
* [Unnatural instructions: Tuning language models with (almost) no human labor](https://arxiv.org/abs/2212.09689) [[arXiv 2022]](https://arxiv.org/abs/2212.09689)
* [From moments to milestones: Incremental timeline summarization leveraging large language models](https://aclanthology.org/2024.acl-long.400/) [[ACL 2024]](https://aclanthology.org/2024.acl-long.400/)
* [On replacing humans with large language models in voice-based human-in-the-loop systems](https://ojs.aaai.org/index.php/AAAI-SS/article/view/28114) [[AAAI Symposium Series 2024]](https://ojs.aaai.org/index.php/AAAI-SS/article/view/28114)
* [Learning from crowdsourced noisy labels: A signal processing perspective](https://arxiv.org/abs/2407.06902) [[arXiv 2024]](https://arxiv.org/abs/2407.06902)
* [Phalm: Building a knowledge graph from scratch by prompting humans and a language model](https://arxiv.org/abs/2310.07170) [[arXiv 2023]](https://arxiv.org/abs/2310.07170)
* [Employing large language models in survey research](https://www.sciencedirect.com/science/article/pii/S2949713X2300021X) [[Natural Language Processing Journal 2023]](https://www.sciencedirect.com/science/article/pii/S2949713X2300021X)
* [Integrating visual context into language models for situated social conversation starters](https://ieeexplore.ieee.org/document/10450099) [[IEEE Transactions on Affective Computing 2024]](https://ieeexplore.ieee.org/document/10450099)
* [Doing personal laps: Llm-augmented dialogue construction for personalized multi-session conversational search](https://dl.acm.org/doi/10.1145/3626772.3657745) [[SIGIR 2024]](https://dl.acm.org/doi/10.1145/3626772.3657745)
* [A survey of reinforcement learning from human feedback](https://arxiv.org/abs/2307.14936) [[arXiv 2024]](https://arxiv.org/abs/2307.14936)
* [Scaling public health text annotation: Zero-shot learning vs. crowdsourcing for improved efficiency and labeling accuracy](https://arxiv.org/abs/2402.06150) [[arXiv 2025]](https://arxiv.org/abs/2402.06150)
* [Generating usage-related questions for preference elicitation in conversational recommender systems](https://dl.acm.org/doi/10.1145/3624345) [[ACM Trans. Recomm. Syst. 2024]](https://dl.acm.org/doi/10.1145/3624345)
* [Principles of explanatory debugging to personalize interactive machine learning](https://dl.acm.org/doi/10.1145/2678025.2701389) [[IUI 2015]](https://dl.acm.org/doi/10.1145/2678025.2701389)
* [Interpretable and interactive learning with human-in-the-loop](https://arxiv.org/abs/1606.05685) [[arXiv 2016]](https://arxiv.org/abs/1606.05685)
* [Can large language models aid in annotating speech emotional data? uncovering new frontiers](https://arxiv.org/abs/2307.06090) [[arXiv 2023]](https://arxiv.org/abs/2307.06090)
* [Artificial intelligence language models and the false fantasy of participatory language policies](https://wpall.journals.yorku.ca/index.php/wpall/article/view/40432) [[Working papers in Applied Linguistics and Linguistics at York 2021]](https://wpall.journals.yorku.ca/index.php/wpall/article/view/40432)
* [Dialogcc: An automated pipeline for creating high-quality multi-modal dialogue dataset](https://arxiv.org/abs/2212.04119) [[arXiv 2022]](https://arxiv.org/abs/2212.04119)
* [A comparative study on annotation quality of crowdsourcing and Ilm via label aggregation](https://ieeexplore.ieee.org/document/10446733) [[ICASSP 2024]](https://ieeexplore.ieee.org/document/10446733)
* [Can Ilm already serve as a database interface? a big bench for large-scale database grounded text-to-sqls](https://proceedings.neurips.cc/paper_files/paper/2023/hash/830ae03f274a0149c4021fa39589a8c4-Abstract-Conference.html) [[NeurIPS 2023]](https://proceedings.neurips.cc/paper_files/paper/2023/hash/830ae03f274a0149c4021fa39589a8c4-Abstract-Conference.html)
* [Synthetic data generation with large language models for text classification: Potential and limitations](https://arxiv.org/abs/2310.07849) [[arXiv 2023]](https://arxiv.org/abs/2310.07849)
* [Faircs-blockchain-based fair crowd-sensing scheme using trusted execution environment](https://www.mdpi.com/1424-8220/20/11/3253) [[Sensors 2020]](https://www.mdpi.com/1424-8220/20/11/3253)
* [Redefining crowdsourced test report prioritization: An innovative approach with large language model](https://www.sciencedirect.com/science/article/pii/S095058492400494X) [[Information and Software Technology 2025]](https://www.sciencedirect.com/science/article/pii/S095058492400494X)
* [Free lunch for user experience: Crowdsourcing agents for scalable user studies](https://arxiv.org/abs/2405.22981) [[arXiv 2025]](https://arxiv.org/abs/2405.22981)
* [Robustifying safety-aligned large language models through clean data curation](https://arxiv.org/abs/2405.19358) [[arXiv 2024]](https://arxiv.org/abs/2405.19358)
* [Trustworthy Ilms: a survey and guideline for evaluating large language models' alignment](https://arxiv.org/abs/2308.05374) [[arXiv 2023]](https://arxiv.org/abs/2308.05374)
* [Neuro-symbolic procedural planning with commonsense prompting](https://arxiv.org/abs/2206.02928) [[arXiv 2022]](https://arxiv.org/abs/2206.02928)
* [Exploring the capabilities of large language models for generating diverse design solutions](https://arxiv.org/abs/2405.02345) [[arXiv 2024]](https://arxiv.org/abs/2405.02345)
* [Words are all you need? language as an approximation for human similarity judgments](https://arxiv.org/abs/2206.04105) [[arXiv 2022]](https://arxiv.org/abs/2206.04105)
* [Hate personified: Investigating the role of llms in content moderation](https://arxiv.org/abs/2310.02657) [[arXiv 2024]](https://arxiv.org/abs/2310.02657)
* [Dynadiffuse: A dynamic diffusion model for continuous time constrained influence maximization](https://ojs.aaai.org/index.php/AAAI/article/view/9265) [[AAAI 2015]](https://ojs.aaai.org/index.php/AAAI/article/view/9265)
* [Characterizing large language models as rationalizers of knowledge-intensive tasks](https://arxiv.org/abs/2311.05085) [[arXiv 2023]](https://arxiv.org/abs/2311.05085)
* [Help me think: A simple prompting strategy for non-experts to create customized content with models](https://arxiv.org/abs/2208.08232) [[arXiv 2022]](https://arxiv.org/abs/2208.08232)
* [Assessing educational quality: Comparative analysis of crowdsourced, expert, and ai-driven rubric applications](https://ojs.aaai.org/index.php/HCOMP/article/view/29648) [[HCOMP 2024]](https://ojs.aaai.org/index.php/HCOMP/article/view/29648)
* [Llms to replace crowdsourcing for parallel data creation? the case of text detoxification](https://aclanthology.org/2023.findings-emnlp.962/) [[EMNLP 2024]](https://aclanthology.org/2023.findings-emnlp.962/)
* [The coughvid crowdsourcing dataset, a corpus for the study of large-scale cough analysis algorithms](https://www.nature.com/articles/s41597-021-00937-4) [[Scientific Data 2021]](https://www.nature.com/articles/s41597-021-00937-4)
* [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155) [[arXiv 2022]](https://arxiv.org/abs/2203.02155)
* [Bleu: a method for automatic evaluation of machine translation](https://aclanthology.org/P02-1040/) [[ACL 2002]](https://aclanthology.org/P02-1040/)
* [Leveraging large language models (llms) to support collaborative human-ai online risk data annotation](https://arxiv.org/abs/2404.07926) [[arXiv 2024]](https://arxiv.org/abs/2404.07926)
* [A practical semi-parametric contextual bandit](https://www.ijcai.org/proceedings/2019/379) [[IJCAI 2019]](https://www.ijcai.org/proceedings/2019/379)
* [A fully automated pipeline for conversational discourse annotation: Tree scheme generation and labeling with large language models](https://arxiv.org/abs/2404.08961) [[arXiv 2025]](https://arxiv.org/abs/2404.08961)
* [Perturbation augmentation for fairer nlp](https://arxiv.org/abs/2108.13242) [[arXiv 2022]](https://arxiv.org/abs/2108.13242)
* [The mask benchmark: Disentangling honesty from accuracy in ai systems](https://arxiv.org/abs/2401.07705) [[arXiv 2025]](https://arxiv.org/abs/2401.07705)
* [Efficiency and effectiveness of Ilm-based summarization of evidence in crowdsourced fact-checking](https://dl.acm.org/doi/10.1145/3688658.3699071) [[SIGIR 2025]](https://dl.acm.org/doi/10.1145/3688658.3699071)
* [Wikichat: Stopping the hallucination of large language model chatbots by few-shot grounding on wikipedia](https://arxiv.org/abs/2305.14292) [[arXiv 2023]](https://arxiv.org/abs/2305.14292)
* [Harnessing large language models for cost-effective relevance labeling in job search systems](https://aaai.org/wp-content/uploads/2024/02/W22_CompJobs24_paper_185.pdf) [[AAAI Workshop 2025]](https://aaai.org/wp-content/uploads/2024/02/W22_CompJobs24_paper_185.pdf)
* [Hollywood in homes: Crowdsourcing data collection for activity understanding](https://arxiv.org/abs/1604.01753) [[arXiv 2016]](https://arxiv.org/abs/1604.01753)
* [Context does matter: Implications for crowdsourced evaluation labels in task-oriented dialogue systems](https://arxiv.org/abs/2404.09980) [[arXiv 2024]](https://arxiv.org/abs/2404.09980)
* [Cheap and fast-but is it good?: evaluating non-expert annotations for natural language tasks](https://aclanthology.org/D08-1027/) [[EMNLP 2008]](https://aclanthology.org/D08-1027/)
* [Minimizing entropy for crowdsourcing with combinatorial multi-armed bandit](https://ieeexplore.ieee.org/document/9534063) [[IEEE INFOCOM 2021]](https://ieeexplore.ieee.org/document/9534063)
* [Parallelparc: A scalable pipeline for generating natural-language analogies](https://arxiv.org/abs/2403.01139) [[arXiv 2024]](https://arxiv.org/abs/2403.01139)
* [Revisiting bundle recommendation for intent-aware product bundling](https://dl.acm.org/doi/10.1145/3638423) [[ACM Transactions on Recommender Systems 2024]](https://dl.acm.org/doi/10.1145/3638423)
* [What do users really ask large language models? an initial log analysis of google bard interactions in the wild](https://dl.acm.org/doi/10.1145/3626772.3657989) [[SIGIR 2024]](https://dl.acm.org/doi/10.1145/3626772.3657989)
* [Llm-driven ontology evaluation: Verifying ontology restrictions with chatgpt](https://link.springer.com/chapter/10.1007/978-3-031-60921-3_16) [[ESWC 2024]](https://link.springer.com/chapter/10.1007/978-3-031-60921-3_16)
* [Near-real-time earthquake-induced fatality estimation using crowdsourced data and large-language models](https://www.sciencedirect.com/science/article/pii/S221242092400392X) [[International Journal of Disaster Risk Reduction 2024]](https://www.sciencedirect.com/science/article/pii/S221242092400392X)
* [Safeguarding crowdsourcing surveys from chatgpt with prompt injection](https://arxiv.org/abs/2306.08833) [[arXiv 2023]](https://arxiv.org/abs/2306.08833)
* [Ferrari: an efficient framework for visual exploratory subgraph search in graph databases](https://link.springer.com/article/10.1007/s00778-020-00637-y) [[The VLDB Journal 2020]](https://link.springer.com/article/10.1007/s00778-020-00637-y)
* [Characterizing crowds to better optimize worker recommendation in crowdsourced testing](https://ieeexplore.ieee.org/document/9082855) [[IEEE Transactions on Software Engineering 2021]](https://ieeexplore.ieee.org/document/9082855)
* [Towards ai-empowered crowdsourcing](https://arxiv.org/abs/2212.14676) [[arXiv 2023]](https://arxiv.org/abs/2212.14676)
* [Crowdsourcing intelligence for improving disaster forecasts](https://www.cell.com/the-innovation/fulltext/S2666-6758(24)00118-0) [[The Innovation 2024]](https://www.cell.com/the-innovation/fulltext/S2666-6758(24)00118-0)
* [Model-in-the-loop (milo): Accelerating multimodal ai data annotation with Ilms](https://arxiv.org/abs/2309.10702) [[arXiv 2024]](https://arxiv.org/abs/2309.10702)
* [Pandalm: An automatic evaluation benchmark for Ilm instruction tuning optimization](https://arxiv.org/abs/2306.05087) [[arXiv 2023]](https://arxiv.org/abs/2306.05087)
* [Reframing human-ai collaboration for generating free-text explanations](https://arxiv.org/abs/2112.08674) [[arXiv 2021]](https://arxiv.org/abs/2112.08674)
* [Aligning crowd-sourced human feedback for reinforcement learning on code generation by large language models](https://ieeexplore.ieee.org/document/10430671) [[IEEE Transactions on Big Data 2024]](https://ieeexplore.ieee.org/document/10430671)
* [Llms as workers in human-computational algorithms? replicating crowdsourcing pipelines with llms](https://dl.acm.org/doi/10.1145/3613905.3650741) [[CHI 2025]](https://dl.acm.org/doi/10.1145/3613905.3650741)
* [The dark side of recruitment in crowdsourcing: Ethics and transparency in micro-task marketplaces](https://link.springer.com/article/10.1007/s10606-023-09477-z) [[Comput. Supported Coop. Work 2023]](https://link.springer.com/article/10.1007/s10606-023-09477-z)
* [Panda: toward partial topology-based search on large networks in a single machine](https://link.springer.com/article/10.1007/s00778-016-0442-y) [[The VLDB Journal 2017]](https://link.springer.com/article/10.1007/s00778-016-0442-y)
* [Panda: a system for partial topology-based search on large networks](http://www.vldb.org/pvldb/vol11/p1966-xie.pdf) [[VLDB 2018]](http://www.vldb.org/pvldb/vol11/p1966-xie.pdf)
* [Cqm: Coverage-constrained quality maximization in crowdsourcing test](https://ieeexplore.ieee.org/document/8103134) [[ICSE-C 2017]](https://ieeexplore.ieee.org/document/8103134)
* [Cocoon: Crowdsourced testing quality maximization under context coverage constraint](https://ieeexplore.ieee.org/document/8102604) [[ISSRE 2017]](https://ieeexplore.ieee.org/document/8102604)
* [Autobandit: A meta bandit online learning system](https://www.ijcai.org/proceedings/2021/363) [[IJCAI 2021]](https://www.ijcai.org/proceedings/2021/363)
* [On the role of large language models in crowdsourcing misinformation assessment](https://ojs.aaai.org/index.php/ICWSM/article/view/28906) [[ICWSM 2024]](https://ojs.aaai.org/index.php/ICWSM/article/view/28906)
* [Instructions as backdoors: Backdoor vulnerabilities of instruction tuning for large language models](https://arxiv.org/abs/2305.14710) [[arXiv 2023]](https://arxiv.org/abs/2305.14710)
* [cost-effective fine-tuning of pre-trained language models with proximal policy optimization](https://arxiv.org/abs/2302.13284) [[arXiv 2024]](https://arxiv.org/abs/2302.13284)
* [Uni-rlhf: Universal platform and benchmark suite for reinforcement learning with diverse human feedback](https://arxiv.org/abs/2307.04279) [[arXiv 2024]](https://arxiv.org/abs/2307.04279)
* [Combining large language models and crowdsourcing for hybrid human-ai misinformation detection](https://dl.acm.org/doi/10.1145/3626772.3657960) [[SIGIR 2024]](https://dl.acm.org/doi/10.1145/3626772.3657960)
* [Efficient data labeling by hierarchical crowdsourcing with large language models](https://aclanthology.org/2024.lrec-main.1001/) [[LREC-COLING 2025]](https://aclanthology.org/2024.lrec-main.1001/)
* [Reasoning about procedures with natural language processing: A tutorial](https://arxiv.org/abs/2201.07436) [[arXiv 2022]](https://arxiv.org/abs/2201.07436)
* [Human-llm collaborative construction of a cantonese emotion lexicon](https://arxiv.org/abs/2310.11526) [[arXiv 2024]](https://arxiv.org/abs/2310.11526)
* [Augesc: Dialogue augmentation with large language models for emotional support conversation](https://arxiv.org/abs/2202.13047) [[arXiv 2022]](https://arxiv.org/abs/2202.13047)
* [Judging llm-as-a-judge with mt-bench and chatbot arena](https://proceedings.neurips.cc/paper_files/paper/2023/hash/334b155b9a845e2c73043d159f0f9b8c-Abstract-Conference.html) [[NeurIPS 2023]](https://proceedings.neurips.cc/paper_files/paper/2023/hash/334b155b9a845e2c73043d159f0f9b8c-Abstract-Conference.html)
```
